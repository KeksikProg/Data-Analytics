from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Export Weather Overall") \
    .config("spark.jars", "/opt/bitnami/spark/user-jars/postgresql-42.7.3.jar") \
    .getOrCreate()

jdbc_url = "jdbc:postgresql://postgres:5432/weather"
connection_props = {
    "user": "airflow",
    "password": "airflow",
    "driver": "org.postgresql.Driver"
}

# –ß—Ç–µ–Ω–∏–µ
df = spark.read.jdbc(jdbc_url, "weather_overall", properties=connection_props)

print(f"üîé –°—Ç—Ä–æ–∫: {df.count()}")
df.show()

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∫ –æ–¥–∏–Ω CSV-—Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
df.coalesce(1).write \
    .mode("overwrite") \
    .option("header", True) \
    .csv("/opt/bitnami/spark/output/weather_overall")

print("‚úÖ CSV export done")
spark.stop()
